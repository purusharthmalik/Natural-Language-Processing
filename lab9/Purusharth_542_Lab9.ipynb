{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "004a8620",
   "metadata": {},
   "source": [
    "# Lab - 9\n",
    "\n",
    "Name: Purusharth Malik\n",
    "\n",
    "Registration No.: 2348542"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559fb33a-2113-4f75-86b7-948d2f889c27",
   "metadata": {},
   "source": [
    "### 1. Implement the Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a2bea6-7f7c-4b28-87b1-089501a474b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def editDistance(str1, str2, m, n):\n",
    "    if m == 0:\n",
    "        return n\n",
    "    if n == 0:\n",
    "        return m\n",
    "\n",
    "    if str1[m-1] == str2[n-1]:\n",
    "        return editDistance(str1, str2, m-1, n-1)\n",
    "    \n",
    "    return 1 + min(editDistance(str1, str2, m, n-1),    # Insert\n",
    "                   editDistance(str1, str2, m-1, n),    # Remove\n",
    "                   editDistance(str1, str2, m-1, n-1)    # Replace\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "910422ac-0941-4d65-bf55-37bfacec763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter First String:sunday\n",
      "Enter Second String:monday\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "str1=input(\"Enter First String:\")\n",
    "str2=input(\"Enter Second String:\")\n",
    "print(editDistance(str1, str2, len(str1), len(str2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa15a0-b69e-4360-bff7-d82d9f008e70",
   "metadata": {},
   "source": [
    "### 2. Implement the Story or Poem Creator based on the keywords using NLG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b244494d-304e-4223-9b19-e3d323707aae",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f40a759-689a-4f04-89c2-06d443ecd92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.utils as ku \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c39e3-a636-4430-bef3-b6b53206fbc2",
   "metadata": {},
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c9b4a40-6344-492a-8b1d-f3e8d6b0f5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words: 4567\n"
     ]
    }
   ],
   "source": [
    "data = open('poem.txt', encoding=\"utf8\").read()\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index)\n",
    " \n",
    "print(\"Total Words:\", total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd3cca-7417-40a2-ad57-54737bbf0400",
   "metadata": {},
   "source": [
    "#### Creating Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c14f08-3b29-4552-9325-f15b48f1a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "predictors, label = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "label = ku.to_categorical(label, num_classes=total_words+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837dd1e5-781e-4979-a2b5-885bdcec52d9",
   "metadata": {},
   "source": [
    "#### Bi-directional LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa90944d-9b28-4b1f-b2c3-9c003d9b8f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 15, 100)           380800    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 15, 300)           301200    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 300)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               160400    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3807)              384507    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3808)              14500864  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15727771 (60.00 MB)\n",
      "Trainable params: 15727771 (60.00 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words+1, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words+1/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words+1, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57276904-7921-477c-a3a1-22449b2fbd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "510/510 [==============================] - 25s 47ms/step - loss: 6.9543 - accuracy: 0.0605\n",
      "Epoch 2/100\n",
      "510/510 [==============================] - 28s 55ms/step - loss: 6.5300 - accuracy: 0.0630\n",
      "Epoch 3/100\n",
      "510/510 [==============================] - 28s 56ms/step - loss: 6.3475 - accuracy: 0.0652\n",
      "Epoch 4/100\n",
      "510/510 [==============================] - 30s 59ms/step - loss: 6.2173 - accuracy: 0.0727\n",
      "Epoch 5/100\n",
      "510/510 [==============================] - 31s 61ms/step - loss: 6.1001 - accuracy: 0.0800\n",
      "Epoch 6/100\n",
      "510/510 [==============================] - 30s 60ms/step - loss: 5.9669 - accuracy: 0.0893\n",
      "Epoch 7/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 5.8469 - accuracy: 0.0991\n",
      "Epoch 8/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 5.7302 - accuracy: 0.1071\n",
      "Epoch 9/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 5.6269 - accuracy: 0.1104\n",
      "Epoch 10/100\n",
      "510/510 [==============================] - 31s 61ms/step - loss: 5.5336 - accuracy: 0.1139\n",
      "Epoch 11/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 5.4425 - accuracy: 0.1180\n",
      "Epoch 12/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 5.3478 - accuracy: 0.1231\n",
      "Epoch 13/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 5.2450 - accuracy: 0.1269\n",
      "Epoch 14/100\n",
      "510/510 [==============================] - 33s 64ms/step - loss: 5.1409 - accuracy: 0.1360\n",
      "Epoch 15/100\n",
      "510/510 [==============================] - 32s 62ms/step - loss: 5.0338 - accuracy: 0.1424\n",
      "Epoch 16/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 4.9220 - accuracy: 0.1517\n",
      "Epoch 17/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 4.8122 - accuracy: 0.1595\n",
      "Epoch 18/100\n",
      "510/510 [==============================] - 36s 70ms/step - loss: 4.7071 - accuracy: 0.1674\n",
      "Epoch 19/100\n",
      "510/510 [==============================] - 36s 70ms/step - loss: 4.5978 - accuracy: 0.1796\n",
      "Epoch 20/100\n",
      "510/510 [==============================] - 79s 156ms/step - loss: 4.4869 - accuracy: 0.1868\n",
      "Epoch 21/100\n",
      "510/510 [==============================] - 34s 66ms/step - loss: 4.3824 - accuracy: 0.1993\n",
      "Epoch 22/100\n",
      "510/510 [==============================] - 36s 71ms/step - loss: 4.2693 - accuracy: 0.2086\n",
      "Epoch 23/100\n",
      "510/510 [==============================] - 34s 66ms/step - loss: 4.1655 - accuracy: 0.2224\n",
      "Epoch 24/100\n",
      "510/510 [==============================] - 32s 62ms/step - loss: 4.0641 - accuracy: 0.2346\n",
      "Epoch 25/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 3.9603 - accuracy: 0.2451\n",
      "Epoch 26/100\n",
      "510/510 [==============================] - 36s 70ms/step - loss: 3.8582 - accuracy: 0.2636\n",
      "Epoch 27/100\n",
      "510/510 [==============================] - 332s 653ms/step - loss: 3.7584 - accuracy: 0.2803\n",
      "Epoch 28/100\n",
      "510/510 [==============================] - 32s 62ms/step - loss: 3.6685 - accuracy: 0.2924\n",
      "Epoch 29/100\n",
      "510/510 [==============================] - 32s 64ms/step - loss: 3.5703 - accuracy: 0.3137\n",
      "Epoch 30/100\n",
      "510/510 [==============================] - 31s 61ms/step - loss: 3.4851 - accuracy: 0.3251\n",
      "Epoch 31/100\n",
      "510/510 [==============================] - 31s 60ms/step - loss: 3.3985 - accuracy: 0.3471\n",
      "Epoch 32/100\n",
      "510/510 [==============================] - 31s 61ms/step - loss: 3.3139 - accuracy: 0.3634\n",
      "Epoch 33/100\n",
      "510/510 [==============================] - 28s 56ms/step - loss: 3.2270 - accuracy: 0.3780\n",
      "Epoch 34/100\n",
      "510/510 [==============================] - 31s 60ms/step - loss: 3.1529 - accuracy: 0.3941\n",
      "Epoch 35/100\n",
      "510/510 [==============================] - 30s 59ms/step - loss: 3.0722 - accuracy: 0.4119\n",
      "Epoch 36/100\n",
      "510/510 [==============================] - 31s 61ms/step - loss: 2.9985 - accuracy: 0.4265\n",
      "Epoch 37/100\n",
      "510/510 [==============================] - 31s 60ms/step - loss: 2.9334 - accuracy: 0.4432\n",
      "Epoch 38/100\n",
      "510/510 [==============================] - 29s 58ms/step - loss: 2.8696 - accuracy: 0.4583\n",
      "Epoch 39/100\n",
      "510/510 [==============================] - 33s 64ms/step - loss: 2.7905 - accuracy: 0.4758\n",
      "Epoch 40/100\n",
      "510/510 [==============================] - 31s 61ms/step - loss: 2.7311 - accuracy: 0.4914\n",
      "Epoch 41/100\n",
      "510/510 [==============================] - 31s 62ms/step - loss: 2.6699 - accuracy: 0.5014\n",
      "Epoch 42/100\n",
      "510/510 [==============================] - 31s 60ms/step - loss: 2.6091 - accuracy: 0.5155\n",
      "Epoch 43/100\n",
      "510/510 [==============================] - 30s 60ms/step - loss: 2.5545 - accuracy: 0.5260\n",
      "Epoch 44/100\n",
      "510/510 [==============================] - 31s 60ms/step - loss: 2.5080 - accuracy: 0.5369\n",
      "Epoch 45/100\n",
      "510/510 [==============================] - 29s 57ms/step - loss: 2.4414 - accuracy: 0.5517\n",
      "Epoch 46/100\n",
      "510/510 [==============================] - 31s 61ms/step - loss: 2.4005 - accuracy: 0.5630\n",
      "Epoch 47/100\n",
      "510/510 [==============================] - 31s 61ms/step - loss: 2.3530 - accuracy: 0.5694\n",
      "Epoch 48/100\n",
      "510/510 [==============================] - 30s 59ms/step - loss: 2.3042 - accuracy: 0.5814\n",
      "Epoch 49/100\n",
      "510/510 [==============================] - 32s 62ms/step - loss: 2.2563 - accuracy: 0.5921\n",
      "Epoch 50/100\n",
      "510/510 [==============================] - 31s 60ms/step - loss: 2.2121 - accuracy: 0.5998\n",
      "Epoch 51/100\n",
      "510/510 [==============================] - 32s 62ms/step - loss: 2.1664 - accuracy: 0.6066\n",
      "Epoch 52/100\n",
      "510/510 [==============================] - 33s 65ms/step - loss: 2.1243 - accuracy: 0.6244\n",
      "Epoch 53/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 2.0910 - accuracy: 0.6249\n",
      "Epoch 54/100\n",
      "510/510 [==============================] - 31s 60ms/step - loss: 2.0525 - accuracy: 0.6343\n",
      "Epoch 55/100\n",
      "510/510 [==============================] - 31s 61ms/step - loss: 2.0372 - accuracy: 0.6384\n",
      "Epoch 56/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 1.9813 - accuracy: 0.6483\n",
      "Epoch 57/100\n",
      "510/510 [==============================] - 31s 61ms/step - loss: 1.9493 - accuracy: 0.6548\n",
      "Epoch 58/100\n",
      "510/510 [==============================] - 32s 62ms/step - loss: 1.9141 - accuracy: 0.6600\n",
      "Epoch 59/100\n",
      "510/510 [==============================] - 29s 56ms/step - loss: 1.9039 - accuracy: 0.6588\n",
      "Epoch 60/100\n",
      "510/510 [==============================] - 31s 60ms/step - loss: 1.8666 - accuracy: 0.6670\n",
      "Epoch 61/100\n",
      "510/510 [==============================] - 30s 59ms/step - loss: 1.8295 - accuracy: 0.6757\n",
      "Epoch 62/100\n",
      "510/510 [==============================] - 29s 57ms/step - loss: 1.8087 - accuracy: 0.6795\n",
      "Epoch 63/100\n",
      "510/510 [==============================] - 29s 58ms/step - loss: 1.7883 - accuracy: 0.6863\n",
      "Epoch 64/100\n",
      "510/510 [==============================] - 30s 59ms/step - loss: 1.7467 - accuracy: 0.6908\n",
      "Epoch 65/100\n",
      "510/510 [==============================] - 33s 65ms/step - loss: 1.7167 - accuracy: 0.6965\n",
      "Epoch 66/100\n",
      "510/510 [==============================] - 33s 64ms/step - loss: 1.6971 - accuracy: 0.7033\n",
      "Epoch 67/100\n",
      "510/510 [==============================] - 32s 62ms/step - loss: 1.6691 - accuracy: 0.7104\n",
      "Epoch 68/100\n",
      "510/510 [==============================] - 33s 64ms/step - loss: 1.6499 - accuracy: 0.7079\n",
      "Epoch 69/100\n",
      "510/510 [==============================] - 31s 61ms/step - loss: 1.6341 - accuracy: 0.7121\n",
      "Epoch 70/100\n",
      "510/510 [==============================] - 32s 62ms/step - loss: 1.6025 - accuracy: 0.7200\n",
      "Epoch 71/100\n",
      "510/510 [==============================] - 32s 62ms/step - loss: 1.5833 - accuracy: 0.7223\n",
      "Epoch 72/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 1.5767 - accuracy: 0.7251\n",
      "Epoch 73/100\n",
      "510/510 [==============================] - 33s 65ms/step - loss: 1.5584 - accuracy: 0.7266\n",
      "Epoch 74/100\n",
      "510/510 [==============================] - 33s 64ms/step - loss: 1.5279 - accuracy: 0.7326\n",
      "Epoch 75/100\n",
      "510/510 [==============================] - 30s 58ms/step - loss: 1.5044 - accuracy: 0.7362\n",
      "Epoch 76/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 1.4810 - accuracy: 0.7411\n",
      "Epoch 77/100\n",
      "510/510 [==============================] - 31s 61ms/step - loss: 1.4764 - accuracy: 0.7413\n",
      "Epoch 78/100\n",
      "510/510 [==============================] - 29s 57ms/step - loss: 1.4448 - accuracy: 0.7499\n",
      "Epoch 79/100\n",
      "510/510 [==============================] - 32s 62ms/step - loss: 1.4359 - accuracy: 0.7485\n",
      "Epoch 80/100\n",
      "510/510 [==============================] - 30s 59ms/step - loss: 1.4225 - accuracy: 0.7496\n",
      "Epoch 81/100\n",
      "510/510 [==============================] - 32s 63ms/step - loss: 1.4037 - accuracy: 0.7526\n",
      "Epoch 82/100\n",
      "510/510 [==============================] - 33s 65ms/step - loss: 1.3931 - accuracy: 0.7557\n",
      "Epoch 83/100\n",
      "510/510 [==============================] - 33s 64ms/step - loss: 1.3712 - accuracy: 0.7608\n",
      "Epoch 84/100\n",
      "510/510 [==============================] - 33s 64ms/step - loss: 1.3659 - accuracy: 0.7582\n",
      "Epoch 85/100\n",
      "510/510 [==============================] - 32s 62ms/step - loss: 1.3486 - accuracy: 0.7636\n",
      "Epoch 86/100\n",
      "510/510 [==============================] - 34s 66ms/step - loss: 1.3272 - accuracy: 0.7668\n",
      "Epoch 87/100\n",
      "510/510 [==============================] - 36s 70ms/step - loss: 1.3182 - accuracy: 0.7694\n",
      "Epoch 88/100\n",
      "510/510 [==============================] - 36s 70ms/step - loss: 1.3031 - accuracy: 0.7730\n",
      "Epoch 89/100\n",
      "510/510 [==============================] - 35s 70ms/step - loss: 1.2915 - accuracy: 0.7759\n",
      "Epoch 90/100\n",
      "510/510 [==============================] - 35s 69ms/step - loss: 1.2882 - accuracy: 0.7718\n",
      "Epoch 91/100\n",
      "510/510 [==============================] - 35s 69ms/step - loss: 1.2718 - accuracy: 0.7789\n",
      "Epoch 92/100\n",
      "510/510 [==============================] - 36s 71ms/step - loss: 1.2564 - accuracy: 0.7789\n",
      "Epoch 93/100\n",
      "510/510 [==============================] - 35s 68ms/step - loss: 1.2509 - accuracy: 0.7820\n",
      "Epoch 94/100\n",
      "510/510 [==============================] - 39s 76ms/step - loss: 1.2279 - accuracy: 0.7856\n",
      "Epoch 95/100\n",
      "510/510 [==============================] - 34s 67ms/step - loss: 1.2300 - accuracy: 0.7835\n",
      "Epoch 96/100\n",
      "510/510 [==============================] - 36s 70ms/step - loss: 1.2184 - accuracy: 0.7851\n",
      "Epoch 97/100\n",
      "510/510 [==============================] - 37s 73ms/step - loss: 1.1989 - accuracy: 0.7885\n",
      "Epoch 98/100\n",
      "510/510 [==============================] - 37s 72ms/step - loss: 1.1985 - accuracy: 0.7870\n",
      "Epoch 99/100\n",
      "510/510 [==============================] - 36s 71ms/step - loss: 1.1897 - accuracy: 0.7877\n",
      "Epoch 100/100\n",
      "510/510 [==============================] - 34s 66ms/step - loss: 1.1843 - accuracy: 0.7903\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(predictors, label, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e177bff4-2995-4435-801b-3be1133fc04d",
   "metadata": {},
   "source": [
    "#### Poem Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b15d42-e42a-44e0-ac9d-514ccb3654ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valley the merry ladies in london were spreading as she stepped away from me and she moved through the fair mountain stout maid thou say god as we say a hummin sweeps it in that pretty fair maid i did salute her every valley fair black i used to frequent do0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = input(\"Enter first few words\")\n",
    "next_words = 50\n",
    "ouptut_text = \"\"\n",
    " \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences(\n",
    "        [token_list], maxlen=max_sequence_len-1,\n",
    "      padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list, \n",
    "                                        verbose=0), axis=-1)\n",
    "    output_word = \"\"\n",
    "     \n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "             \n",
    "    seed_text += \" \" + output_word\n",
    "     \n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae90e2b",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
